{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pre-trained NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import cPickle as pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy\n",
    "from scipy.misc import imread, imsave, imresize\n",
    "from lasagne.utils import floatX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# copyright: see http://www.robots.ox.ac.uk/~vgg/research/very_deep/\n",
    "\n",
    "\n",
    "from lasagne.layers import InputLayer\n",
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.layers import NonlinearityLayer\n",
    "from lasagne.layers import DropoutLayer\n",
    "from lasagne.layers import Pool2DLayer as PoolLayer\n",
    "from lasagne.layers import Conv2DLayer as ConvLayer\n",
    "from lasagne.nonlinearities import softmax\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    net = {}\n",
    "    net['input'] = InputLayer((None, 3, 224, 224))\n",
    "    net['conv1_1'] = ConvLayer(\n",
    "        net['input'], 64, 3, pad=1, flip_filters=False)\n",
    "    net['conv1_2'] = ConvLayer(\n",
    "        net['conv1_1'], 64, 3, pad=1, flip_filters=False)\n",
    "    net['pool1'] = PoolLayer(net['conv1_2'], 2)\n",
    "    net['conv2_1'] = ConvLayer(\n",
    "        net['pool1'], 128, 3, pad=1, flip_filters=False)\n",
    "    net['conv2_2'] = ConvLayer(\n",
    "        net['conv2_1'], 128, 3, pad=1, flip_filters=False)\n",
    "    net['pool2'] = PoolLayer(net['conv2_2'], 2)\n",
    "    net['conv3_1'] = ConvLayer(\n",
    "        net['pool2'], 256, 3, pad=1, flip_filters=False)\n",
    "    net['conv3_2'] = ConvLayer(\n",
    "        net['conv3_1'], 256, 3, pad=1, flip_filters=False)\n",
    "    net['conv3_3'] = ConvLayer(\n",
    "        net['conv3_2'], 256, 3, pad=1, flip_filters=False)\n",
    "    net['pool3'] = PoolLayer(net['conv3_3'], 2)\n",
    "    net['conv4_1'] = ConvLayer(\n",
    "        net['pool3'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv4_2'] = ConvLayer(\n",
    "        net['conv4_1'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv4_3'] = ConvLayer(\n",
    "        net['conv4_2'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['pool4'] = PoolLayer(net['conv4_3'], 2)\n",
    "    net['conv5_1'] = ConvLayer(\n",
    "        net['pool4'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv5_2'] = ConvLayer(\n",
    "        net['conv5_1'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv5_3'] = ConvLayer(\n",
    "        net['conv5_2'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['pool5'] = PoolLayer(net['conv5_3'], 2)\n",
    "    net['fc6'] = DenseLayer(net['pool5'], num_units=4096)\n",
    "    net['fc6_dropout'] = DropoutLayer(net['fc6'], p=0.5)\n",
    "    net['fc7'] = DenseLayer(net['fc6_dropout'], num_units=4096)\n",
    "    net['fc7_dropout'] = DropoutLayer(net['fc7'], p=0.5)\n",
    "    net['fc8'] = DenseLayer(\n",
    "        net['fc7_dropout'], num_units=1000, nonlinearity=None)\n",
    "    net['prob'] = NonlinearityLayer(net['fc8'], softmax)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ostrich, Struthio camelus\n"
     ]
    }
   ],
   "source": [
    "#classes' names are stored here\n",
    "classes = pickle.load(open('classes.pkl'))\n",
    "#for example, 10th class is ostrich:\n",
    "print classes[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to implement two functions in the cell below.\n",
    "\n",
    "Preprocess function should take the image with shape (w, h, 3) and transform it into a tensor with shape (1, 3, 224, 224). Without this transformation, vgg19 won't be able to digest input image. \n",
    "Additionally, your preprocessing function have to rearrange channels RGB -> BGR and subtract mean values from every channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MEAN_VALUES = np.array([104, 117, 123])\n",
    "IMAGE_W = 224\n",
    "\n",
    "def preprocess(img):\n",
    "    img = <convert RGB to BGR>\n",
    "    \n",
    "    img = <substract mean>\n",
    "    \n",
    "    #convert from [w,h,3 to 1,3,w,h]\n",
    "    img = np.transpose(img, (2, 0, 1))[None]\n",
    "    return img\n",
    "\n",
    "def deprocess(img):\n",
    "    img = img.reshape(img.shape[1:]).transpose((1, 2, 0))\n",
    "    for i in xrange(3):\n",
    "        img[:,:, i] += MEAN_VALUES[i]\n",
    "    return img[:, :, :: -1].astype(np.uint8)\n",
    "\n",
    "img = (np.random.rand(IMAGE_W, IMAGE_W, 3) * 256).astype(np.uint8)\n",
    "\n",
    "print np.linalg.norm(deprocess(preprocess(img)) - img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your implementation is correct, the number above will be small, because deprocess function is the inverse of preprocess function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wget https://s3.amazonaws.com/lasagne/recipes/pretrained/imagenet/vgg16.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('vgg16.pkl') as f:\n",
    "    weights = pickle.load(f)\n",
    "    \n",
    "<load weights into the network>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_image = T.tensor4('input')\n",
    "output = lasagne.layers.get_output(net['prob'], input_image)\n",
    "prob = theano.function([input_image], output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check\n",
    "Давайте проверим, что загруженная сеть работает. Для этого мы скормим ей картину альбатроса и проверим, что она правильно его распознаёт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = imread('sample_images/albatross.jpg')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "p = prob(preprocess(img))\n",
    "\n",
    "labels = p.ravel().argsort()[-1:-6:-1]\n",
    "print 'top-5 classes are:'\n",
    "for l in labels:\n",
    "    print '%3f\\t%s' % (p.ravel()[l], classes[l].split(',')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cats Vs Dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Тут стоит загрузить выборку котиков, как вы делали в прошлом семинаре. Картинки должны стать 224x224x3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grand-quest\n",
    "\n",
    "Основная задача - научиться решать предыдущую задачу(cats vs dogs) гораздо лучше при помощи предобученной сети.\n",
    "\n",
    "Начать лучше всего с того, что получить выход с одного из полносвязных слоёв (fc6 или fc7) и по нему классифицировать котиков/собачек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Если вдруг будет время"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On higher layers, filters have more than 3 channels, so it is impossible to visualize them directly. However, of we want to understand something about features on higher layers, it is possible to visualize them via optimization of the input image.\n",
    "\n",
    "Namely, we can solve the following problem\n",
    "\n",
    "$$J=\\mathrm{argmax} \\left( n^i_{xyc}(I) \\right)$$\n",
    "\n",
    "there $n^i_{xyc}$ is the activation of neuron on $i$'th layer in position $x$,$y$,$c$ given input image $I$.\n",
    "Basically, $J$ is the answer on a question \"what our neuron is looking for?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'theano' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9a2879f21a9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgenerated_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloatX\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMAGE_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMAGE_W\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mgen_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlasagne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerated_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgen_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'pool1'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'theano' is not defined"
     ]
    }
   ],
   "source": [
    "generated_image = theano.shared(floatX(np.zeros((1, 3, IMAGE_W, IMAGE_W))))\n",
    "gen_features = lasagne.layers.get_output(net.values(), generated_image)\n",
    "gen_features = {k: v for k, v in zip(net.keys(), gen_features)}\n",
    "\n",
    "layer_name = 'pool1'\n",
    "c = 0\n",
    "blob_width = gen_features[layer_name].shape[2]\n",
    "x = blob_width/2\n",
    "y = blob_width/2\n",
    "activation_loss = 1e10*(1e1 - gen_features[layer_name][0, c, x, y])**2\n",
    "\n",
    "tv_loss = T.mean(T.abs_(generated_image[:,:,1:,1:] - generated_image[:,:,:-1,1:]) +\n",
    "                 T.abs_(generated_image[:,:,1:,1:] - generated_image[:,:,1:,:-1]))\n",
    "\n",
    "loss = activation_loss + 1.0 * tv_loss\n",
    "\n",
    "grad = T.grad(loss, generated_image)\n",
    "\n",
    "f_loss = theano.function([], loss)\n",
    "f_grad = theano.function([], grad)\n",
    "\n",
    "# Helper functions to interface with scipy.optimize\n",
    "def eval_loss(x0):\n",
    "    x_ = floatX(x0.reshape((1, 3, IMAGE_W, IMAGE_W)))\n",
    "    generated_image.set_value(x_)\n",
    "    return f_loss().astype('float64')\n",
    "\n",
    "def eval_grad(x0):\n",
    "    x0 = floatX(x0.reshape((1, 3, IMAGE_W, IMAGE_W)))\n",
    "    generated_image.set_value(x0)\n",
    "    return np.array(f_grad()).flatten().astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generated_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-036b14efa427>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#run input image optimization via scipy.optimize.fmin_l_bfgs_b\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgenerated_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloatX\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMAGE_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMAGE_W\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mx0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerated_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float64'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmin_l_bfgs_b\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfprime\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_grad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxfun\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerated_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float64'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'generated_image' is not defined"
     ]
    }
   ],
   "source": [
    "#run input image optimization via scipy.optimize.fmin_l_bfgs_b\n",
    "generated_image.set_value(floatX(np.zeros((1, 3, IMAGE_W, IMAGE_W))))\n",
    "x0 = generated_image.get_value().astype('float64')\n",
    "status = scipy.optimize.fmin_l_bfgs_b(eval_loss, x0.flatten(), fprime=eval_grad, maxfun=20)\n",
    "x0 = generated_image.get_value().astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your **deprocess** function is implemented correctly, you'll see that the neuron on the first pooling layer is looking for. The result should look like gabor filter, simular to ones found in the first layer of networks with large filters, such as AlexNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#show the results\n",
    "w = IMAGE_W\n",
    "for d in [112, 64, 32, 16, 8]:\n",
    "    pic = deprocess(x0)[w/2-d:w/2+d,w/2-d:w/2+d,:]\n",
    "    pic -= pic.min()\n",
    "    pic /= pic.max()\n",
    "    plt.imshow(pic, interpolation='None')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional problem:\n",
    "Adjust the code above to work with neurons on fc8 layer.\n",
    "\n",
    "\n",
    "fc8 neurons are wired to output classes, so maximization of neuron value will produce an image which contains as much of given class (from the point of view of neural network) as possible. \n",
    "\n",
    "Examples of such images are shown at:\n",
    "\n",
    "http://yosinski.com/deepvis\n",
    "\n",
    "http://googleresearch.blogspot.ru/2015/06/inceptionism-going-deeper-into-neural.html\n",
    "\n",
    "http://auduno.com/post/125362849838/visualizing-googlenet-classes\n",
    "\n",
    "https://317070.github.io/Dream/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
