{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pre-trained NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2:\n",
    "задача - \n",
    "* научить sklearn-класификатор (например, RandomForestClassifier) на cats vs dogs, используя как признаки ответы нейронки\n",
    "* оценить качество (accuracy / roc_auc) по тесту\n",
    "* использовать предпоследний слой нейронки вместо последнего\n",
    "\n",
    "Делать это рекоммендуется у себя на ПК или на everware (т.е. НЕ в binder, ибо долго)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!conda install -y mkl >log\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import cPickle as pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy\n",
    "from scipy.misc import imread, imsave, imresize\n",
    "from lasagne.utils import floatX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# copyright: see http://www.robots.ox.ac.uk/~vgg/research/very_deep/\n",
    "from lasagne.layers import InputLayer\n",
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.layers import NonlinearityLayer\n",
    "from lasagne.layers import DropoutLayer\n",
    "from lasagne.layers import Pool2DLayer as PoolLayer\n",
    "from lasagne.layers import Conv2DLayer as ConvLayer\n",
    "from lasagne.nonlinearities import softmax\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    net = {}\n",
    "    net['input'] = InputLayer((None, 3, 224, 224))\n",
    "    net['conv1_1'] = ConvLayer(\n",
    "        net['input'], 64, 3, pad=1, flip_filters=False)\n",
    "    net['conv1_2'] = ConvLayer(\n",
    "        net['conv1_1'], 64, 3, pad=1, flip_filters=False)\n",
    "    net['pool1'] = PoolLayer(net['conv1_2'], 2)\n",
    "    net['conv2_1'] = ConvLayer(\n",
    "        net['pool1'], 128, 3, pad=1, flip_filters=False)\n",
    "    net['conv2_2'] = ConvLayer(\n",
    "        net['conv2_1'], 128, 3, pad=1, flip_filters=False)\n",
    "    net['pool2'] = PoolLayer(net['conv2_2'], 2)\n",
    "    net['conv3_1'] = ConvLayer(\n",
    "        net['pool2'], 256, 3, pad=1, flip_filters=False)\n",
    "    net['conv3_2'] = ConvLayer(\n",
    "        net['conv3_1'], 256, 3, pad=1, flip_filters=False)\n",
    "    net['conv3_3'] = ConvLayer(\n",
    "        net['conv3_2'], 256, 3, pad=1, flip_filters=False)\n",
    "    net['pool3'] = PoolLayer(net['conv3_3'], 2)\n",
    "    net['conv4_1'] = ConvLayer(\n",
    "        net['pool3'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv4_2'] = ConvLayer(\n",
    "        net['conv4_1'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv4_3'] = ConvLayer(\n",
    "        net['conv4_2'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['pool4'] = PoolLayer(net['conv4_3'], 2)\n",
    "    net['conv5_1'] = ConvLayer(\n",
    "        net['pool4'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv5_2'] = ConvLayer(\n",
    "        net['conv5_1'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv5_3'] = ConvLayer(\n",
    "        net['conv5_2'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['pool5'] = PoolLayer(net['conv5_3'], 2)\n",
    "    net['fc6'] = DenseLayer(net['pool5'], num_units=4096)\n",
    "    net['fc6_dropout'] = DropoutLayer(net['fc6'], p=0.5)\n",
    "    net['fc7'] = DenseLayer(net['fc6_dropout'], num_units=4096)\n",
    "    net['fc7_dropout'] = DropoutLayer(net['fc7'], p=0.5)\n",
    "    net['fc8'] = DenseLayer(\n",
    "        net['fc7_dropout'], num_units=1000, nonlinearity=None)\n",
    "    net['prob'] = NonlinearityLayer(net['fc8'], softmax)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#classes' names are stored here\n",
    "classes = pickle.load(open('classes.pkl'))\n",
    "#for example, 10th class is ostrich:\n",
    "print classes[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to implement two functions in the cell below.\n",
    "\n",
    "Preprocess function should take the image with shape (w, h, 3) and transform it into a tensor with shape (1, 3, 224, 224). Without this transformation, vgg19 won't be able to digest input image. \n",
    "Additionally, your preprocessing function have to rearrange channels RGB -> BGR and subtract mean values from every channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MEAN_VALUES = np.array([104, 117, 123])\n",
    "IMAGE_W = 224\n",
    "\n",
    "def preprocess(img):\n",
    "    img = img[:,:,::-1].astype('float')\n",
    "    \n",
    "    for i in xrange(3):\n",
    "        img[:,:, i] -= MEAN_VALUES[i]\n",
    "    #convert from [w,h,3 to 1,3,w,h]\n",
    "    img = np.transpose(img, (2, 0, 1))[None]\n",
    "    return img\n",
    "\n",
    "def deprocess(img):\n",
    "    img = img.reshape(img.shape[1:]).transpose((1, 2, 0))\n",
    "    for i in xrange(3):\n",
    "        img[:,:, i] += MEAN_VALUES[i]\n",
    "    return img[:, :, :: -1].astype(np.uint8)\n",
    "\n",
    "img = (np.random.rand(IMAGE_W, IMAGE_W, 3) * 256).astype(np.uint8)\n",
    "\n",
    "print np.linalg.norm(deprocess(preprocess(img)) - img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your implementation is correct, the number above will be small, because deprocess function is the inverse of preprocess function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wget https://s3.amazonaws.com/lasagne/recipes/pretrained/imagenet/vgg16.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('vgg16.pkl') as f:\n",
    "    weights = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "lasagne.layers.set_all_param_values(net[\"prob\"],weights['param values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_image = T.tensor4('input')\n",
    "output = lasagne.layers.get_output(net['prob'], input_image,deterministic=True)\n",
    "prob = theano.function([input_image], output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#example: getting the intermediate layer\n",
    "#output = lasagne.layers.get_output(net['fc6'], input_image,deterministic=True)\n",
    "#partial = theano.function([input_image], output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check\n",
    "Давайте проверим, что загруженная сеть работает. Для этого мы скормим ей картину альбатроса и проверим, что она правильно его распознаёт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imresize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = imresize(imread('sample_images/albatross.jpg'), (224,224))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "p = prob(preprocess(img))\n",
    "\n",
    "labels = p.ravel().argsort()[-1:-10:-1]\n",
    "print 'top-5 classes are:'\n",
    "for l in labels:\n",
    "    print '%3f\\t%s' % (p.ravel()[l], classes[l].split(',')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cats Vs Dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/d61lupw909hc785/dogs_vs_cats.train.zip?dl=1 -O data.zip\n",
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "X = []\n",
    "Y = []\n",
    "for fname in tqdm(os.listdir('train/')):\n",
    "    y = fname.startswith(\"cat\")\n",
    "    img = imread(\"train/\"+fname)\n",
    "\n",
    "    Y.append(y)\n",
    "    X.append(prob(preprocess(imresize(img,(224,224)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grand-quest\n",
    "\n",
    "Основная задача - научиться решать предыдущую задачу(cats vs dogs) гораздо лучше при помощи предобученной сети.\n",
    "\n",
    "Начать лучше всего с того, что получить выход с одного из полносвязных слоёв (fc6 или fc7) и по нему классифицировать котиков/собачек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_features = np.concatenate(X)\n",
    "\n",
    "#crop if we ended prematurely\n",
    "Y = Y[:len(x_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression().fit(x_features,np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_classes = np.argsort(np.abs(model.coef_[0]))[::-1]\n",
    "\n",
    "for i in top_classes:\n",
    "    print classes[i], model.coef_[0,i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### TODO:\n",
    "* Честно посчитать точность предсказания (accuracy, auc) логрегрессии и random forest\n",
    "* Попытаться подобрать оптимальную модель\n",
    "* попытаться использовать данные с предпоследнего слоя нейронки вместо последнего\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Если вдруг будет время, про визуализацию vgg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On higher layers, filters have more than 3 channels, so it is impossible to visualize them directly. However, of we want to understand something about features on higher layers, it is possible to visualize them via optimization of the input image.\n",
    "\n",
    "Namely, we can solve the following problem\n",
    "\n",
    "$$J=\\mathrm{argmax} \\left( n^i_{xyc}(I) \\right)$$\n",
    "\n",
    "there $n^i_{xyc}$ is the activation of neuron on $i$'th layer in position $x$,$y$,$c$ given input image $I$.\n",
    "Basically, $J$ is the answer on a question \"what our neuron is looking for?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generated_image = theano.shared(floatX(np.zeros((1, 3, IMAGE_W, IMAGE_W))))\n",
    "gen_features = lasagne.layers.get_output(net.values(), generated_image)\n",
    "gen_features = {k: v for k, v in zip(net.keys(), gen_features)}\n",
    "\n",
    "layer_name = 'pool1'\n",
    "c = 0\n",
    "blob_width = gen_features[layer_name].shape[2]\n",
    "x = blob_width/2\n",
    "y = blob_width/2\n",
    "activation_loss = 1e10*(1e1 - gen_features[layer_name][0, c, x, y])**2\n",
    "\n",
    "tv_loss = T.mean(T.abs_(generated_image[:,:,1:,1:] - generated_image[:,:,:-1,1:]) +\n",
    "                 T.abs_(generated_image[:,:,1:,1:] - generated_image[:,:,1:,:-1]))\n",
    "\n",
    "loss = activation_loss + 1.0 * tv_loss\n",
    "\n",
    "grad = T.grad(loss, generated_image)\n",
    "\n",
    "f_loss = theano.function([], loss)\n",
    "f_grad = theano.function([], grad)\n",
    "\n",
    "# Helper functions to interface with scipy.optimize\n",
    "def eval_loss(x0):\n",
    "    x_ = floatX(x0.reshape((1, 3, IMAGE_W, IMAGE_W)))\n",
    "    generated_image.set_value(x_)\n",
    "    return f_loss().astype('float64')\n",
    "\n",
    "def eval_grad(x0):\n",
    "    x0 = floatX(x0.reshape((1, 3, IMAGE_W, IMAGE_W)))\n",
    "    generated_image.set_value(x0)\n",
    "    return np.array(f_grad()).flatten().astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#run input image optimization via scipy.optimize.fmin_l_bfgs_b\n",
    "generated_image.set_value(floatX(np.zeros((1, 3, IMAGE_W, IMAGE_W))))\n",
    "x0 = generated_image.get_value().astype('float64')\n",
    "status = scipy.optimize.fmin_l_bfgs_b(eval_loss, x0.flatten(), fprime=eval_grad, maxfun=20)\n",
    "x0 = generated_image.get_value().astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your **deprocess** function is implemented correctly, you'll see that the neuron on the first pooling layer is looking for. The result should look like gabor filter, simular to ones found in the first layer of networks with large filters, such as AlexNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#show the results\n",
    "w = IMAGE_W\n",
    "for d in [112, 64, 32, 16, 8]:\n",
    "    pic = deprocess(x0)[w/2-d:w/2+d,w/2-d:w/2+d,:]\n",
    "    pic -= pic.min()\n",
    "    pic /= pic.max()\n",
    "    plt.imshow(pic, interpolation='None')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional problem:\n",
    "Adjust the code above to work with neurons on fc8 layer.\n",
    "\n",
    "\n",
    "fc8 neurons are wired to output classes, so maximization of neuron value will produce an image which contains as much of given class (from the point of view of neural network) as possible. \n",
    "\n",
    "Examples of such images are shown at:\n",
    "\n",
    "http://yosinski.com/deepvis\n",
    "\n",
    "http://googleresearch.blogspot.ru/2015/06/inceptionism-going-deeper-into-neural.html\n",
    "\n",
    "http://auduno.com/post/125362849838/visualizing-googlenet-classes\n",
    "\n",
    "https://317070.github.io/Dream/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
